{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e0472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d6b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train test data and transform into usable form\n",
    "train = pd.read_json(\"../data/train_preprocessed.json\")\n",
    "test = pd.read_json(\"../data/test.json\")\n",
    "\n",
    "X_train, y_train = train.drop(columns=[\"has_spoiler\"]), train[\"has_spoiler\"]\n",
    "X_test, y_test = test.drop(columns=[\"has_spoiler\"]), test[\"has_spoiler\"]\n",
    "\n",
    "inputs_train = {\n",
    "\"user_id\": X_train[\"user_id\"].values,\n",
    "\"book_id\": X_train[\"book_id\"].values,\n",
    "\"numerics\": X_train[[\"rating\", \"n_votes\", \"n_comments\"]].values\n",
    "}\n",
    "\n",
    "inputs_test = {\n",
    "\"user_id\": X_test[\"user_id\"].values,\n",
    "\"book_id\": X_test[\"book_id\"].values,\n",
    "\"numerics\": X_test[[\"rating\", \"n_votes\", \"n_comments\"]].values\n",
    "}\n",
    "\n",
    "user_max = X_train.user_id.max()\n",
    "book_max = X_train.book_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e69f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(keras.Model):\n",
    "    def __init__(self, user_max, book_max, user_emb_size=16, book_emb_size=12):\n",
    "        super(mModel, self).__init__()\n",
    "        \n",
    "        # create embeddings\n",
    "        self.user_embedding = keras.layers.Embedding(input_dim=user_max+3, output_dim=user_emb_size, input_length=1, name=\"user_embedding\")\n",
    "        self.book_embedding = keras.layers.Embedding(input_dim=book_max+3, output_dim=book_emb_size,input_length=1, name=\"book_embedding\")\n",
    "        \n",
    "        # this layer will only be used for numeric features\n",
    "        self.numerics = keras.Sequential([\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "        ])\n",
    "        \n",
    "        # this part will be used for combination of numeric feats and user_id/book_id features\n",
    "        self.dense_layers = keras.Sequential([\n",
    "            keras.layers.Dense(128, activation=\"relu\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "              \n",
    "    def call(self, inputs):\n",
    "        user_id_input = inputs[\"user_id\"]\n",
    "        book_id_input = inputs[\"book_id\"]\n",
    "        numerics = inputs[\"numerics\"]\n",
    "        user_embedded = self.user_embedding(user_id_input)\n",
    "        book_embedded = self.book_embedding(book_id_input)\n",
    "        user_flattened = keras.layers.Flatten()(user_embedded)\n",
    "        book_flattened = keras.layers.Flatten()(book_embedded)\n",
    "        \n",
    "        numerics = self.numerics(numerics) # only numerics\n",
    "        concatenated = keras.layers.Concatenate()([user_flattened, book_flattened, numerics]) # all features\n",
    "        out = self.dense_layers(concatenated)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbf8b81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1656/1656 [==============================] - 9s 4ms/step - loss: 0.6749 - auc: 0.5364 - val_loss: 0.6431 - val_auc: 0.5559\n",
      "Epoch 2/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.6021 - auc: 0.5545 - val_loss: 0.5807 - val_auc: 0.5658\n",
      "Epoch 3/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.5422 - auc: 0.5723 - val_loss: 0.5230 - val_auc: 0.5842\n",
      "Epoch 4/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.4857 - auc: 0.5936 - val_loss: 0.4715 - val_auc: 0.6055\n",
      "Epoch 5/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.4344 - auc: 0.6215 - val_loss: 0.4160 - val_auc: 0.6317\n",
      "Epoch 6/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.3900 - auc: 0.6565 - val_loss: 0.3765 - val_auc: 0.6551\n",
      "Epoch 7/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.3537 - auc: 0.6898 - val_loss: 0.3448 - val_auc: 0.6814\n",
      "Epoch 8/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.3253 - auc: 0.7195 - val_loss: 0.3189 - val_auc: 0.7008\n",
      "Epoch 9/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.3041 - auc: 0.7442 - val_loss: 0.3046 - val_auc: 0.7150\n",
      "Epoch 10/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.2890 - auc: 0.7635 - val_loss: 0.2938 - val_auc: 0.7260\n",
      "Epoch 11/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.2783 - auc: 0.7795 - val_loss: 0.2879 - val_auc: 0.7352\n",
      "Epoch 12/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.2709 - auc: 0.7915 - val_loss: 0.2856 - val_auc: 0.7413\n",
      "Epoch 13/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.2652 - auc: 0.8023 - val_loss: 0.2834 - val_auc: 0.7469\n",
      "Epoch 14/20\n",
      "1656/1656 [==============================] - 7s 4ms/step - loss: 0.2612 - auc: 0.8103 - val_loss: 0.2829 - val_auc: 0.7501\n",
      "Epoch 15/20\n",
      "1656/1656 [==============================] - 7s 5ms/step - loss: 0.2575 - auc: 0.8175 - val_loss: 0.2823 - val_auc: 0.7525\n",
      "Epoch 16/20\n",
      "1656/1656 [==============================] - 8s 5ms/step - loss: 0.2544 - auc: 0.8240 - val_loss: 0.2817 - val_auc: 0.7554\n",
      "Epoch 17/20\n",
      "1656/1656 [==============================] - 8s 5ms/step - loss: 0.2516 - auc: 0.8291 - val_loss: 0.2821 - val_auc: 0.7568\n",
      "Epoch 18/20\n",
      "1656/1656 [==============================] - 8s 5ms/step - loss: 0.2494 - auc: 0.8334 - val_loss: 0.2818 - val_auc: 0.7581\n",
      "Epoch 19/20\n",
      "1656/1656 [==============================] - 8s 5ms/step - loss: 0.2472 - auc: 0.8375 - val_loss: 0.2831 - val_auc: 0.7578\n",
      "Epoch 20/20\n",
      "1656/1656 [==============================] - 8s 5ms/step - loss: 0.2451 - auc: 0.8414 - val_loss: 0.2841 - val_auc: 0.7566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21a9a11c310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train the model\n",
    "model = Model(user_max, book_max)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(inputs_train, y_train, epochs=20, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481177a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EVALUATION CELL\n",
    "\n",
    "preds = model.predict(inputs_test, batch_size=512, verbose=0)\n",
    "\n",
    "# selects best threshold value\n",
    "thresholds = np.linspace(0,0.5,100)\n",
    "best = 0\n",
    "best_th = None\n",
    "for th in thresholds:\n",
    "    f1 = f1_score(y_test, (preds>th).astype(int))\n",
    "    if f1 > best:\n",
    "        best = f1\n",
    "        best_th = th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ece056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90    119401\n",
      "           1       0.27      0.48      0.35     13041\n",
      "\n",
      "    accuracy                           0.82    132442\n",
      "   macro avg       0.60      0.67      0.62    132442\n",
      "weighted avg       0.87      0.82      0.84    132442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints report\n",
    "print(classification_report(y_test, (preds>best_th).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c5773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
