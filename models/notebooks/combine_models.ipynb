{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yh4f0iKwgDaH"
   },
   "outputs": [],
   "source": [
    "train_path = \"../../data/train_preprocessed.json\"\n",
    "test_path = \"../../data/test.json\"\n",
    "embeddings_path = \"../../data/glove.6B.200d.txt\"\n",
    "lstm_model_path =  \"../pretrained_models/lstm_model\"\n",
    "mlp_model_path = \"../pretrained_models/mlp_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BVW522M2gDst"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from models import LSTM_model, MLP_model\n",
    "import tensorflow as tf\n",
    "from utils import embeddings, read_data\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjN1AVIOgIOB",
    "outputId": "1e6b6bf6-c80e-42b2-fd02-e05e70109ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data\n"
     ]
    }
   ],
   "source": [
    "# FIRST MODEL\n",
    "max_words = 5000\n",
    "embedding_dim = 200\n",
    "\n",
    "datasets = read_dataset(train_path, test_path, max_words, balance_test=True)\n",
    "trainx_lstm, trainy_lstm, testx_lstm, testy_lstm, tokenizer, max_seq_length = datasets[\"lstm_data\"]\n",
    "trainx_mlp, trainy_mlp, testx_mlp, testy_mlp, user_max, book_max = datasets[\"mlp_data\"]\n",
    "\n",
    "print(\"Prepared Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TO7XFsUZ958C"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = embeddings(embeddings_path, embedding_dim, tokenizer, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rSfTIW8sUX_P"
   },
   "outputs": [],
   "source": [
    "lstm_model = LSTM_model(max_words, embedding_dim, embedding_matrix, max_seq_length)\n",
    "lstm_model.load_weights(lstm_model_path)\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Jawd2py8sYvV"
   },
   "outputs": [],
   "source": [
    "# SECOND MODEL\n",
    "\n",
    "mlp_model = MLP_model(user_max, book_max, user_emb_size=24, book_emb_size=16)\n",
    "mlp_model.load_weights(mlp_model_path)\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\", Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MbXMTWqbnrt4"
   },
   "outputs": [],
   "source": [
    "def decrease_data_size(inputs_lstm, labels_lstm, inputs_mlp, labels_mlp, l=None):\n",
    "    if not l:\n",
    "        return inputs_lstm, labels_lstm, inputs_mlp, labels_mlp\n",
    "    user_ids = inputs_mlp[\"user_id\"][:l]\n",
    "    book_ids = inputs_mlp[\"book_id\"][:l]\n",
    "    numerics = inputs_mlp[\"numerics\"][:l]\n",
    "    new_labels_mlp = labels_mlp[:l]\n",
    "    new_inputs_mlp = {\n",
    "    \"user_id\": user_ids,\n",
    "    \"book_id\": book_ids,\n",
    "    \"numerics\": numerics\n",
    "    }\n",
    "    new_inputs_lstm = inputs_lstm[:l]\n",
    "    new_labels_lstm = labels_lstm[:l]\n",
    "\n",
    "    return new_inputs_lstm, new_labels_lstm, new_inputs_mlp, new_labels_mlp\n",
    "\n",
    "tiny_xtrain_lstm, tiny_ytrain_lstm, tiny_xtrain_mlp, tiny_ytrain_mlp = decrease_data_size(trainx_lstm, trainy_lstm, trainx_mlp, trainy_mlp)\n",
    "tiny_xtest_lstm, tiny_ytest_lstm, tiny_xtest_mlp, tiny_ytest_mlp = decrease_data_size(testx_lstm, testy_lstm, testx_mlp, testy_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3-hQUbomlag",
    "outputId": "729de735-b655-41bb-d7e3-6f3d678f030c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749/1749 [==============================] - 266s 152ms/step\n",
      "3498/3498 [==============================] - 8s 2ms/step\n",
      "517/517 [==============================] - 78s 152ms/step\n",
      "1033/1033 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_train_logits = lstm_model.predict(tiny_xtrain_lstm, batch_size=64)\n",
    "mlp_train_logits = mlp_model.predict(tiny_xtrain_mlp)\n",
    "classifier_train_input = np.concatenate((lstm_train_logits, mlp_train_logits), axis=1)\n",
    "classifier_train_labels = tiny_ytrain_lstm.copy()\n",
    "\n",
    "lstm_test_logits = lstm_model.predict(tiny_xtest_lstm, batch_size=64)\n",
    "mlp_test_logits = mlp_model.predict(tiny_xtest_mlp)\n",
    "classifier_test_input = np.concatenate((lstm_test_logits, mlp_test_logits), axis=1)\n",
    "classifier_test_labels = tiny_ytest_lstm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fM17TgT9oHTR",
    "outputId": "50ff184d-0f8a-40cc-95e6-626c90ef68ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: F1 - 0.7367603550295857\n",
      "ada_boost: F1 - 0.7536296793938717\n",
      "svc: F1 - 0.758206977771235\n",
      "logistic_regression: F1 - 0.7583729371702279\n",
      "knn: F1 - 0.7361503726274827\n",
      "naive_bayesian: F1 - 0.7587133368161804\n",
      "xgb: F1 - 0.756371952344067\n",
      "Best model: naive_bayesian | Score: 0.7587133368161804\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\"random_forest\": RandomForestClassifier(),\n",
    "                   \"ada_boost\": AdaBoostClassifier(),\n",
    "                   \"svc\": SVC(),\n",
    "                   \"logistic_regression\": LogisticRegression(),\n",
    "                   \"knn\": KNeighborsClassifier(),\n",
    "                   \"naive_bayesian\": GaussianNB(),\n",
    "                   \"xgb\": XGBClassifier()}\n",
    "\n",
    "best = {\"model\": None, \"score\": 0}\n",
    "for model_name in classifiers.keys():\n",
    "    curr = classifiers[model_name]\n",
    "    curr.fit(classifier_train_input, classifier_train_labels)\n",
    "    preds = curr.predict(classifier_test_input)\n",
    "    score = f1_score(tiny_ytest_lstm, preds)\n",
    "    if score > best[\"score\"]:\n",
    "        best[\"model\"] = model_name\n",
    "        best[\"score\"] = score\n",
    "    print(f\"{model_name}: F1 - {score}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Best model: {best['model']} | Score: {best['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwVWR_Pnthdl",
    "outputId": "9045704e-2679-407b-8645-1c1788b33f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM    : Acc: 0.7723 | Precision: 0.6984 | Recall: 0.7450 | F1: 0.7209 | AUC: 0.8532\n",
      "MLP     : Acc: 0.6939 | Precision: 0.5997 | Recall: 0.6751 | F1: 0.6352 | AUC: 0.7609\n",
      "Ensemble: Acc: 0.8043 | Precision: 0.7392 | Recall: 0.7792 | F1: 0.7587 | AUC: 0.7999713398742909\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(lstm_model, mlp_model, classifier, lstm_in, lstm_lab, mlp_in, mlp_lab):\n",
    "\n",
    "    _, lstm_acc, lstm_precision, lstm_recall = lstm_model.evaluate(lstm_in, lstm_lab, verbose=0, batch_size=256)\n",
    "    lstm_f1 = 2*lstm_recall*lstm_precision / (lstm_recall+lstm_precision)\n",
    "    lstm_auc = roc_auc_score(tiny_ytest_lstm, lstm_test_logits)\n",
    "    _, mlp_acc, mlp_precision, mlp_recall = mlp_model.evaluate(mlp_in, mlp_lab, verbose=0, batch_size=256)\n",
    "    mlp_f1 = 2*mlp_recall*mlp_precision / (mlp_recall+mlp_precision)\n",
    "    mlp_auc = roc_auc_score(tiny_ytest_mlp, mlp_test_logits)\n",
    "\n",
    "    classifier_preds_binary = classifier.predict(classifier_test_input)\n",
    "    classifier_acc = accuracy_score(tiny_ytest_lstm, classifier_preds_binary)\n",
    "    classifier_precision = precision_score(tiny_ytest_lstm, classifier_preds_binary)\n",
    "    classifier_recall = recall_score(tiny_ytest_lstm, classifier_preds_binary)\n",
    "    classifier_f1 = 2*classifier_recall*classifier_precision / (classifier_recall+classifier_precision)\n",
    "    classifier_auc = roc_auc_score(tiny_ytest_lstm, classifier_preds_binary)\n",
    "\n",
    "    print(f\"LSTM    : Acc: {lstm_acc:.4f} | Precision: {lstm_precision:.4f} | Recall: {lstm_recall:.4f} | F1: {lstm_f1:.4f} | AUC: {lstm_auc:.4f}\")\n",
    "    print(f\"MLP     : Acc: {mlp_acc:.4f} | Precision: {mlp_precision:.4f} | Recall: {mlp_recall:.4f} | F1: {mlp_f1:.4f} | AUC: {mlp_auc:.4f}\")\n",
    "    print(f\"Ensemble: Acc: {classifier_acc:.4f} | Precision: {classifier_precision:.4f} | Recall: {classifier_recall:.4f} | F1: {classifier_f1:.4f} | AUC: {classifier_auc:.4f}\")\n",
    "\n",
    "evaluate_models(lstm_model, mlp_model, classifiers[best[\"model\"]], tiny_xtest_lstm, tiny_ytest_lstm, tiny_xtest_mlp, tiny_ytest_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Jjmow9jIMciE"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../pretrained_models/classifier.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
