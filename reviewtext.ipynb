{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6927b39",
   "metadata": {},
   "source": [
    "## Melisa / 05.11.2023\n",
    "### Data Preprocessing\n",
    "#### Task: Preprocess ’review text’ Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5006b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnltk.download(\"stopwords\")\\nnltk.download(\"punkt\")\\nnltk.download(\"wordnet\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\"\"\"\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2510f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d94e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/spoiler.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18a014",
   "metadata": {},
   "source": [
    "### DOING THE PREPROCESSING ON A SINGULAR DATA POINT TO MAKE SURE ALL IS WELL.\n",
    "## TODO: TURN ALL OF THIS INTO A FUNCTION SO YOU CAN USE APPLY FUNCTION TO THE DATAFRAME ON THE MAIN SOURCE FILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78412c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_review_text(val):\n",
    "    clean_test = []\n",
    "    for sentence in val:\n",
    "        # Tokenize the sentence\n",
    "        words = word_tokenize(sentence[1])\n",
    "        # Lowercase and remove non-alphanumeric characters\n",
    "        words = [word.lower() for word in words if word.isalnum()]\n",
    "        # Remove stopwords \n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        # Append the cleaned sentence to the cleaned dataset\n",
    "        \n",
    "        #LEMMATIZATION ÇOK BİR ŞEY DEĞİŞTİRMİYOR, YETERLİ Mİ YOKSA STEMMİNG Mİ YAPMALIYIZ? İLERDE DURUMA GÖRE BURAYA GERİ DÖN\n",
    "        normalized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        clean_test.append(normalized_words)\n",
    "        \n",
    "    \n",
    "    # Build a vocabulary\n",
    "    vocab = set(word for sentence in clean_test for word in sentence)\n",
    "    word_to_index = {word: index for index, word in enumerate(vocab)}\n",
    "\n",
    "    # NUMERICAL REPRESENTATION\n",
    "    numerical_data = [[word_to_index[word] for word in sentence] for sentence in clean_test]\n",
    "    \n",
    "    \n",
    "    # Padding sequences / BAŞLANGIÇ OLARAK 13 SEÇTİM AMA CÜMLE UZUNLUĞU MEANİ 8, OLABİLDİĞİNCE ACCURATE OLSUN DİYE. EĞER HIZDAN DOLAYI\n",
    "    # SIKINTI YAŞAMAYA BAŞLARSAK BURAYI 8-13 ARASI GİTTİKÇE AŞAĞI ÇEKEBİLİRİZ.\n",
    "    max_sequence_length = 13\n",
    "    padded_data = [seq[:max_sequence_length] + [0] * max(0, max_sequence_length - len(seq)) for seq in numerical_data]\n",
    "    \n",
    "    \n",
    "    padded_data = torch.tensor(padded_data)\n",
    "\n",
    "    #SPOILER LABELS\n",
    "    label_lst = [i[0] for i in val]\n",
    "    labels = torch.tensor(label_lst)\n",
    "\n",
    "    dataset = TensorDataset(padded_data, labels)\n",
    "    #print(padded_data)    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1cc06e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n",
      "<bound method NDFrame.describe of 0        (([tensor(10), tensor(28), tensor(0), tensor(0...\n",
      "1        (([tensor(5), tensor(2), tensor(0), tensor(0),...\n",
      "2        (([tensor(129), tensor(33), tensor(149), tenso...\n",
      "3        (([tensor(10), tensor(5), tensor(8), tensor(6)...\n",
      "4        (([tensor(135), tensor(17), tensor(34), tensor...\n",
      "                               ...                        \n",
      "19995    (([tensor(28), tensor(0), tensor(34), tensor(1...\n",
      "19996    (([tensor(28), tensor(14), tensor(11), tensor(...\n",
      "19997    (([tensor(6), tensor(4), tensor(11), tensor(9)...\n",
      "19998    (([tensor(12), tensor(21), tensor(0), tensor(0...\n",
      "19999    (([tensor(0), tensor(8), tensor(0), tensor(0),...\n",
      "Name: test, Length: 20000, dtype: object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-74252055dc8f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  smaller_df[\"test\"] = smaller_df[\"review_sentences\"].apply(process_review_text)\n"
     ]
    }
   ],
   "source": [
    "# WORKING ON A SMALL SUBSET FOR NOW JUST TO MAKE SURE EVERYTHING WORKS\n",
    "smaller_df = df.iloc[:20000]\n",
    "#print(smaller_df.shape)\n",
    "\n",
    "smaller_df[\"test\"] = smaller_df[\"review_sentences\"].apply(process_review_text)\n",
    "#print(smaller_df[\"test\"].describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94101e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
